{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.load(\"data/test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\miniconda3\\envs\\trust-me\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\trust-me\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "baseline = models.resnet50(pretrained=True)\n",
    "    \n",
    "baseline.fc = nn.Linear(2048, 910)\n",
    "    \n",
    "if os.path.exists(f\"models/baseline.pt\"):\n",
    "    baseline.load_state_dict(torch.load(f\"models/baseline.pt\"))\n",
    "\n",
    "baseline.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\miniconda3\\envs\\trust-me\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\trust-me\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "triplet = models.resnet18(pretrained=True)\n",
    "    \n",
    "    \n",
    "if os.path.exists(f\"models/resnet18_9.pt\"):\n",
    "    triplet.load_state_dict(torch.load(f\"models/resnet18_9.pt\"))\n",
    "\n",
    "triplet.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(embeddings, targets):\n",
    "    embeddings = np.array(embeddings)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # Get cosine similarity for all embeddings\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Fill diagonal with inf\n",
    "    np.fill_diagonal(similarity_matrix, -np.inf)\n",
    "    \n",
    "    # Find the index of max sim for each embedding\n",
    "    most_similar_indices = np.argmax(similarity_matrix, axis=1)\n",
    "    \n",
    "    # Extract the labels of the most similar items\n",
    "    predicted_labels = [targets[i] for i in most_similar_indices]\n",
    "    n_correct = sum(1 for true, pred in zip(targets, predicted_labels) if true == pred)\n",
    "    \n",
    "    accuracy = 100 * (n_correct / len(embeddings))\n",
    "    \n",
    "    return accuracy, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, dataloader, device):\n",
    "    embeddings = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            data = inputs.to(device)\n",
    "            label = labels.to(device)\n",
    "            batch_emb, batch_lab = [], []            \n",
    "            \n",
    "            emb = model(data)\n",
    "            \n",
    "            batch_emb.extend(emb.cpu())\n",
    "            batch_lab.extend(label.cpu().tolist())\n",
    "            \n",
    "            embeddings.extend(batch_emb)\n",
    "            targets.extend(batch_lab)\n",
    "            \n",
    "    return embeddings, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "baseline = baseline.to(device)\n",
    "\n",
    "baseline_emb, baseline_targ = get_embeddings(baseline, test_dataloader, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(baseline_emb)):\n",
    "    baseline_emb[i] = baseline_emb[i].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(baseline_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy, baseline_preds = get_accuracy(baseline_emb, baseline_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = triplet.to(device)\n",
    "triplet_emb, triplet_targ = get_embeddings(triplet, test_dataloader, \"cuda\")\n",
    "\n",
    "for i in range(len(triplet_emb)):\n",
    "    triplet_emb[i] = triplet_emb[i].detach().numpy()\n",
    "\n",
    "triplet_accuracy, triplet_preds = get_accuracy(triplet_emb, triplet_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set with 75576 samples of 400 classes.\n",
      "Baseline model openset performance: 79.31486186090822\n",
      "Triplet model openset performance: 3.810733566211496\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set with {len(test_dataset)} samples of {len(set(test_dataset.labels))} classes.\")\n",
    "print(f\"Baseline model openset performance: {baseline_accuracy}\")\n",
    "print(f\"Triplet model openset performance: {triplet_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trust-me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
