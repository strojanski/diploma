{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import resnet50,  resnet18\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          5.19615242 10.39230485]\n",
      " [ 5.19615242  0.          5.19615242]\n",
      " [10.39230485  5.19615242  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "# Example vectors (rows in a matrix)\n",
    "vectors = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# Compute pairwise Euclidean distances\n",
    "distances = cdist(vectors, vectors, 'euclidean')\n",
    "\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.load(\"data/test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "baseline = resnet50(pretrained=True)\n",
    "    \n",
    "baseline.fc = nn.Linear(2048, 910)\n",
    "    \n",
    "if os.path.exists(f\"models/baseline.pt\"):\n",
    "    baseline.load_state_dict(torch.load(f\"models/baseline.pt\"))\n",
    "\n",
    "baseline.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "triplet = models.squeezenet1_1(pretrained=True)\n",
    "    \n",
    "triplet.classifier = torch.nn.Identity()\n",
    "\n",
    "bs = 1024\n",
    "\n",
    "if os.path.exists(f\"models/squeezenet_{bs}.pt\"):\n",
    "    triplet.load_state_dict(torch.load(f\"models/squeezenet_{bs}.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(embeddings, targets):\n",
    "    embeddings = np.array(embeddings)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    # Get cosine similarity for all embeddings\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Fill diagonal with inf\n",
    "    np.fill_diagonal(similarity_matrix, -np.inf)\n",
    "    \n",
    "    # Find the index of max sim for each embedding\n",
    "    most_similar_indices = np.argmax(similarity_matrix, axis=1)\n",
    "    \n",
    "    # Extract the labels of the most similar items\n",
    "    predicted_labels = [targets[i] for i in most_similar_indices]\n",
    "    n_correct = sum(1 for true, pred in zip(targets, predicted_labels) if true == pred)\n",
    "    \n",
    "    accuracy = 100 * (n_correct / len(embeddings))\n",
    "    \n",
    "    return accuracy, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, dataloader, device):\n",
    "    embeddings = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            data = inputs.to(device)\n",
    "            label = labels.to(device)\n",
    "            batch_emb, batch_lab = [], []            \n",
    "            \n",
    "            emb = model(data)\n",
    "            \n",
    "            batch_emb.extend(emb.cpu())\n",
    "            batch_lab.extend(label.cpu().tolist())\n",
    "            \n",
    "            embeddings.extend(batch_emb)\n",
    "            targets.extend(batch_lab)\n",
    "            \n",
    "    return embeddings, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, 128, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.to(device)\n",
    "\n",
    "baseline_emb, baseline_targ = get_embeddings(baseline, test_dataloader, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(baseline_emb)):\n",
    "    baseline_emb[i] = baseline_emb[i].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(baseline_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_accuracy, baseline_preds = get_accuracy(baseline_emb, baseline_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = triplet.to(device)\n",
    "triplet_emb, triplet_targ = get_embeddings(triplet, test_dataloader, \"cuda\")\n",
    "\n",
    "for i in range(len(triplet_emb)):\n",
    "    triplet_emb[i] = triplet_emb[i].detach().numpy()\n",
    "\n",
    "triplet_accuracy, triplet_preds = get_accuracy(triplet_emb, triplet_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set with 75576 samples of 400 classes.\n",
      "Triplet model openset performance: 40.66105642002752\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set with {len(test_dataset)} samples of {len(set(test_dataset.labels))} classes.\")\n",
    "# print(f\"Baseline model openset performance: {baseline_accuracy}\")\n",
    "print(f\"Triplet model openset performance: {triplet_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Compare best model performances to majority classifier and specify that the bad model still has some knowledge. Also use random classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trust-me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
