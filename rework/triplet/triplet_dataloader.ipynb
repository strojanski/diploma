{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from preprocess import resize_input, train_test_split, read_raw\n",
    "from ear_triplet import EarTriplet\n",
    "\n",
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = np.loadtxt(\"./train_500.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "data_path = \"../UERC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ear_data = os.listdir(data_path)\n",
    "\n",
    "ear_imgs = {}\n",
    "for person in ear_data:\n",
    "    if int(person) not in train_subjects:\n",
    "        continue\n",
    "    \n",
    "    imgs = os.listdir(\"%s/%s\" % (data_path, person))\n",
    "    try:\n",
    "        ear_imgs[person] = [\n",
    "            cv2.cvtColor(\n",
    "                np.asarray(Image.open(f\"{data_path}/{person}/{img}\")), cv2.COLOR_BGR2RGB\n",
    "            )\n",
    "            for img in imgs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_triplets(X, y):\n",
    "    # Constraint: anchor and positive must be the same person\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    print(\"Classes: \", len(np.unique(y)))\n",
    "\n",
    "    # Key has a list of indices of instances of that label\n",
    "    # label_to_indices[label] returns indices of all the instances of class=label\n",
    "    label_to_indices = {label: np.where(y == label)[0] for label in np.unique(y)}\n",
    "    \n",
    "    for key in label_to_indices.keys():\n",
    "        np.random.shuffle(label_to_indices[key])\n",
    "\n",
    "    an, pos, neg = [], [], []\n",
    "\n",
    "    # For each class\n",
    "    for i, label in enumerate(label_to_indices.keys()):\n",
    "        subarray_size = len(label_to_indices[label]) // 2\n",
    "        \n",
    "        # Get random negative classes; negs = array of classes\n",
    "        negs = np.random.choice(list(label_to_indices.keys()), size=subarray_size, replace=False)\n",
    "        while label in negs:\n",
    "            negs = np.random.choice(list(label_to_indices.keys()), size=subarray_size, replace=False)\n",
    "\n",
    "        # anchor and positive have label = label and negative is random\n",
    "        an.extend(label_to_indices[label][:subarray_size])\n",
    "        pos.extend(label_to_indices[label][subarray_size:][:subarray_size])\n",
    "        \n",
    "        # Negative = random class od vseh ostalih, vzami random instanco iz vsakega\n",
    "        for neg_label in negs:\n",
    "            neg.extend(np.random.choice(label_to_indices[neg_label], size=1))\n",
    "\n",
    "    print(len(an), len(pos), len(neg))\n",
    "\n",
    "    # Use the resulting arrays of indices to get the split arrays\n",
    "    anchor_data, anchor_labels = X[an], y[an]\n",
    "    positive_data, positive_labels = X[pos], y[pos]\n",
    "    negative_data, negative_labels = X[neg], y[neg]\n",
    "        \n",
    "    return (anchor_data, anchor_labels), (positive_data, positive_labels), (negative_data, negative_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(ear_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastijan/anaconda3/envs/torch/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  362\n",
      "2474 2474 2474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2474, 2474, 2474, 2474, 2474, 2474)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = resize_input(X_train, mode=\"train\")\n",
    "\n",
    "train_triplets = split_triplets(X_train, y_train)\n",
    "\n",
    "train_anc, train_pos, train_neg = train_triplets\n",
    "\n",
    "train_dataset = EarTriplet(train_anc[0], train_anc[1], train_pos[0], train_pos[1], train_neg[0], train_neg[1])\n",
    "\n",
    "len(train_dataset.anchor_data), len(train_dataset.anchor_labels), len(train_dataset.positive_data), len(train_dataset.positive_labels), len(train_dataset.negative_data), len(train_dataset.negative_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.save(train_dataset, \"data/train_dataset_500.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = resize_input(X_eval, mode=\"test\")\n",
    "\n",
    "eval_triplets = split_triplets(X_eval, y_eval)\n",
    "\n",
    "eval_anc, eval_pos, eval_neg = eval_triplets\n",
    "\n",
    "eval_dataset = EarTriplet(eval_anc[0], eval_anc[1], eval_pos[0], eval_pos[1], eval_neg[0], eval_neg[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(eval_dataset, \"data/eval_dataset_500.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
